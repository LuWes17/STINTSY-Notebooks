{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaQNYV8FNPvr"
      },
      "source": [
        "You don't have to code anything here, just read and follow along. You will need to process `hdf5` files in the binomial logistic regression notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGiRZyD6NPvs"
      },
      "source": [
        "# Reading and Writing `hdf5` Files\n",
        "\n",
        "Most of the time, your data will be in separate files which will be stored in separate spaces in your memory (especially true for image data). This is not efficient since we have to load the data one by one during training. A better way is to store all the data into one file so they are mapped in a contiguous space in the memory. However, this will pose another problem when your data is too big to fit in your memory. Memory mapped file systems / databases such as HDF5 addresses this problem by directly reading data from your storage and only loading the data you are currently reading into memory. It also provides a seemless interface that works as if you are working with a giant matrix.\n",
        "\n",
        "**In this notebook, you will learn to:**\n",
        "- Write data into an hdf5 file\n",
        "    - store (multiple) data sets in one hdf5 file\n",
        "- Read data from an hdf5 file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfvlM4kpNPvt"
      },
      "source": [
        "## Instructions\n",
        "* You may not reproduce this notebook or share them to anyone."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgvJxpDENPvt"
      },
      "source": [
        "## Installing the `h5py` and `pillow` packages\n",
        "\n",
        "Don't forget to install the `h5py` package and `Pillow` to read and write images.\n",
        "\n",
        "- `pip install Pillow`\n",
        "- `pip install h5py`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rwhGtt7XNPvt"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import h5py\n",
        "import imageio\n",
        "import numpy as np\n",
        "from scipy import misc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Adr9FFHNNPvt"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "For this exercise, we will be working with $64 \\times 64$ images stored as separate `png` files in the `cat_train` and `cat_test` folders. If you do not have the `cat_train` and `cat_test` folders, kindly extract these folders in the `cat.zip` file. The folders also include a text file (`labels.txt`) that encodes the ground truth labels for each image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WVGSjNcYNPvt"
      },
      "outputs": [],
      "source": [
        "train_path = 'cat_train'\n",
        "test_path = 'cat_test'\n",
        "\n",
        "# get the list of file names in each folder\n",
        "train_filenames = []\n",
        "files = sorted(os.listdir(train_path))\n",
        "for file in files:\n",
        "    if file.endswith('.png'):\n",
        "        train_filenames.append('/'.join([train_path, file]))\n",
        "\n",
        "test_filenames = []\n",
        "files = sorted(os.listdir(test_path))\n",
        "for file in files:\n",
        "    if file.endswith('.png'):\n",
        "        test_filenames.append('/'.join([test_path, file]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHsAo6-ANPvu"
      },
      "source": [
        "Display the number of images in the train and test sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M4GBxsZXNPvu"
      },
      "outputs": [],
      "source": [
        "num_train = len(train_filenames)\n",
        "num_test = len(test_filenames)\n",
        "\n",
        "print('Number of train images =', num_train)\n",
        "print('Number of test images =', num_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfMk21TvNPvu"
      },
      "source": [
        "## Create `hdf5` file\n",
        "\n",
        "Create a blank `hdf5` file. You can think of this as a dictionary which can store data referenced/indexed by keys."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "3LOVPPY_NPvu"
      },
      "outputs": [],
      "source": [
        "file_name = 'cat_dataset.hdf5'\n",
        "save_file = h5py.File(file_name, 'w')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mY84WQ21NPvu"
      },
      "source": [
        "The `create_dataset()` function adds keys to your `hdf5` file. The important parameters are:\n",
        "- Name of the key\n",
        "- Shape of the dataset - for images, it is usually in the `(N, H, W, C)` format, where `N` is the number of images, `H` is the height in pixels, `W` is the width in pixels, and `C` is the number of channels (which is set to 3 for colored images represented in RGB).\n",
        "- Data type"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8Cw1f8SNPvu"
      },
      "source": [
        "## Store train images in the `hdf5` file\n",
        "\n",
        "Let's use `train_x` as key to store the train images and `train_y` to store the train labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ep72Cai_NPvu"
      },
      "outputs": [],
      "source": [
        "image_height = 64\n",
        "image_width = 64\n",
        "\n",
        "# create datasets for the train images and labels\n",
        "train_images = save_file.create_dataset('train_x', shape=(num_train, image_height, image_width, 3), dtype='float32')\n",
        "train_labels = save_file.create_dataset('train_y', shape=(num_train, 1), dtype='int32')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghZO46GZNPvu"
      },
      "source": [
        "Using the `imageio.imread()` function, read the train images stored in the folder `cat_train`. Normalize the images to `[0, 1]` by dividing the pixel values by 255 and store it in the `hdf5` file under the `train_x` key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SsJDPKItNPvu"
      },
      "outputs": [],
      "source": [
        "for i in range(num_train):\n",
        "    image = imageio.imread(train_filenames[i])\n",
        "    train_images[i] = image / 255."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_Cz_GW1NPvu"
      },
      "source": [
        "Randomly read data to check if the write operation was successful."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sviFgHvNNPvu"
      },
      "outputs": [],
      "source": [
        "random_index = np.arange(num_train)\n",
        "np.random.shuffle(random_index)\n",
        "plt.figure(figsize=(6, 6))\n",
        "\n",
        "for i in range(9):\n",
        "    plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(train_images[random_index[i]])\n",
        "    plt.axis('off')\n",
        "    plt.title(random_index[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-h7VeI7NPvu"
      },
      "source": [
        "## Store test images in the `hdf5` file\n",
        "\n",
        "Let's use `test_x` as key to store the train images and `test_y` to store the train labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9iBp4eFcNPvu"
      },
      "outputs": [],
      "source": [
        "test_images = save_file.create_dataset('test_x', shape=(num_test, image_height, image_width, 3), dtype='float32')\n",
        "test_labels = save_file.create_dataset('test_y', shape=(num_test, 1), dtype='int32')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqWD3TrrNPvu"
      },
      "source": [
        "Using the `imageio.imread()` function, read the test images stored in the folder `cat_test`. Normalize the images to `[0, 1]` by dividing the pixel values by 255 and store it in the `hdf5` file under the `test_x` key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Oagt6iONPvv"
      },
      "outputs": [],
      "source": [
        "for i in range(num_test):\n",
        "    image = imageio.imread(test_filenames[i])\n",
        "    test_images[i] = image / 255."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IrzenjvNPvv"
      },
      "source": [
        "Randomly read data to check if the write operation was successful."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ht7iTVvbNPvv"
      },
      "outputs": [],
      "source": [
        "random_index = np.arange(num_test)\n",
        "np.random.shuffle(random_index)\n",
        "plt.figure(figsize=(6, 6))\n",
        "for i in range(9):\n",
        "    plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(test_images[random_index[i]])\n",
        "    plt.axis('off')\n",
        "    plt.title(random_index[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pGFhyH0NPvv"
      },
      "source": [
        "## Read and store the labels of the train and test images in the `hdf5` file\n",
        "\n",
        "Read the corresponding labels for the train and test images. Labels of the train images are stored as `train_y`, while labels of the test images are stored as `test_y`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0sGnKBI-NPvv"
      },
      "outputs": [],
      "source": [
        "with open(train_path + '/labels.txt','r') as file:\n",
        "    i = 0\n",
        "    for l in file:\n",
        "        train_labels[i] = int(l)\n",
        "        i += 1\n",
        "\n",
        "with open(test_path + '/labels.txt','r') as file:\n",
        "    i = 0\n",
        "    for l in file:\n",
        "        test_labels[i] = int(l)\n",
        "        i += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1dq46T0NPvv"
      },
      "source": [
        "Close the `hdf5` file writer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dHlNPSevNPvv"
      },
      "outputs": [],
      "source": [
        "save_file.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qs4E_zH1NPvv"
      },
      "source": [
        "## Read `hdf5` file that you just created\n",
        "\n",
        "Open the `hdf5` file in read mode."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SQm_OMSeNPvv"
      },
      "outputs": [],
      "source": [
        "read_hdf5 = h5py.File(file_name, 'r')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OHyfahZNPvv"
      },
      "source": [
        "Print the existing keys inside the `hdf5` file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wHP3CNOPNPvv"
      },
      "outputs": [],
      "source": [
        "for key in read_hdf5.keys():\n",
        "    print(key)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYx9NC-7NPvv"
      },
      "source": [
        "Print the shape of the train images, train labels, test images, and test labels in the `hdf5` file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cGhVu90oNPvv"
      },
      "outputs": [],
      "source": [
        "print('Train images shape =', read_hdf5['train_x'].shape)\n",
        "print('Train labels shape =', read_hdf5['train_y'].shape)\n",
        "print('Test images shape =', read_hdf5['test_x'].shape)\n",
        "print('Test labels shape =', read_hdf5['test_y'].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUAINQo5NPvv"
      },
      "source": [
        "Randomly read and show train images stored in the `hdf5` file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7r4QJ6qpNPvv"
      },
      "outputs": [],
      "source": [
        "random_index = np.arange(num_train)\n",
        "np.random.shuffle(random_index)\n",
        "plt.figure(figsize=(6, 6))\n",
        "for i in range(9):\n",
        "    plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(read_hdf5['train_x'][random_index[i]])\n",
        "    plt.axis('off')\n",
        "    plt.title('Idx = ' + str(random_index[i]) +', y = ' + str(read_hdf5['train_y'][random_index[i]]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEPLO5fiNPvv"
      },
      "source": [
        "Randomly read and show train images stored in the `hdf5` file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RVBsdnflNPvv"
      },
      "outputs": [],
      "source": [
        "random_index = np.arange(num_test)\n",
        "np.random.shuffle(random_index)\n",
        "plt.figure(figsize=(6, 6))\n",
        "for i in range(9):\n",
        "    plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(read_hdf5['test_x'][random_index[i]])\n",
        "    plt.axis('off')\n",
        "    plt.title('Idx = ' + str(random_index[i]) +', y = ' + str(read_hdf5['test_y'][random_index[i]]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMnIyJ68NPvv"
      },
      "source": [
        "Close the `hdf5` file reader."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eVyZcaQ-NPvv"
      },
      "outputs": [],
      "source": [
        "read_hdf5.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsPsXLvMNPvw"
      },
      "source": [
        "<center><b>fin</b></center>"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}